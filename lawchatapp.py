#VSCodeë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ íŒŒì¼ì…ë‹ˆë‹¤. Releaseì— ìˆëŠ” LawChatì„ ìœ„í•œ ë°ì´í„° íŒŒì¼ì— ìˆëŠ” _documents.pklê³¼ _embeddings.pklê³¼ í•¨ê»˜ ì‹¤í–‰ì‹œí‚¤ë©´ ë©ë‹ˆë‹¤.
#.envíŒŒì¼ì€ ê°œì¸ì •ë³´ë¥¼ ìœ„í•´ ë”°ë¡œ ì˜¬ë¦¬ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 

import streamlit as st
import pickle
import os
import faiss
import numpy as np
import re

from dotenv import load_dotenv
from openai import OpenAI

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document

from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
# --------------------------------------------------------------------------
# 0. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# --------------------------------------------------------------------------
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), ".env"))

GENERAL_API_KEY  = os.getenv("GENERAL_API_KEY")
FINETUNE_API_KEY = os.getenv("FINETUNE_API_KEY")

if GENERAL_API_KEY is None:
    raise ValueError("âŒ GENERAL_API_KEYê°€ .envì—ì„œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
if FINETUNE_API_KEY is None:
    raise ValueError("âŒ FINETUNE_API_KEYê°€ .envì—ì„œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

os.environ["OPENAI_API_KEY"] = str(GENERAL_API_KEY)

finetune_client = OpenAI(api_key=str(FINETUNE_API_KEY))
general_client  = OpenAI(api_key=str(GENERAL_API_KEY))

FINETUNED_MODEL_ID = "ft:gpt-4.1-mini-2025-04-14:dbdbdeep::CiuSaiDu"

# --------------------------------------------------------------------------
# 1. ê³„ì•½ì„œ ë¬¸ì„œ + ì„ë² ë”© ë¡œë“œ
# --------------------------------------------------------------------------
@st.cache_resource
def load_docs_and_vectors():
    with open(r"C:\í…ìŠ¤íŠ¸ë°ì´í„°ë¶„ì„(1ì¡°)\í…ìŠ¤íŠ¸ë°ì´í„°ë¶„ì„(1ì¡°)\ê³„ì•½_documents.pkl", "rb") as f:
        docs = pickle.load(f)
    with open(r"C:\í…ìŠ¤íŠ¸ë°ì´í„°ë¶„ì„(1ì¡°)\í…ìŠ¤íŠ¸ë°ì´í„°ë¶„ì„(1ì¡°)\ê³„ì•½_embeddings.pkl", "rb") as f:
        vectors = pickle.load(f)
    return docs, vectors

# --------------------------------------------------------------------------
# 2. FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
# --------------------------------------------------------------------------
@st.cache_resource
def create_vectorstore(_docs, _vectors):
    dim = len(_vectors[0])
    index = faiss.IndexFlatL2(dim)
    index.add(np.array(_vectors).astype("float32"))

    wrapped_docs = [
        Document(page_content=d) if isinstance(d, str) else d
        for d in _docs
    ]

    doc_dict = {str(i): wrapped_docs[i] for i in range(len(wrapped_docs))}
    docstore = InMemoryDocstore(doc_dict)
    index_to_docstore_id = {i: str(i) for i in range(len(wrapped_docs))}

    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=str(GENERAL_API_KEY)
    )

    vectorstore = FAISS(
        embedding_function=embeddings,
        index=index,
        docstore=docstore,
        index_to_docstore_id=index_to_docstore_id,
    )
    return vectorstore

# --------------------------------------------------------------------------
# 3. RAG ì²´ì¸
# --------------------------------------------------------------------------
@st.cache_resource
def initialize_rag_chain(_vectorstore):
    retriever = _vectorstore.as_retriever(search_kwargs={"k": 3})

    qa_prompt = ChatPromptTemplate.from_messages([
        ("system",
         """ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°í•­ ê²€ìƒ‰ AIì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µí•˜ì„¸ìš”.
âš ï¸ ë¬¸ì„œì˜ íŒŒì¼ëª…ì´ë‚˜ ì‹ë³„ìëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

{context}"""),
        ("human", "{input}")
    ])

    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=0,
        api_key=str(GENERAL_API_KEY)
    )

    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)

    return rag_chain

# --------------------------------------------------------------------------
# 4. íŒŒì¸íŠœë‹ LLM (ì‰¬ìš´ ì„¤ëª…)
# --------------------------------------------------------------------------
def explain_with_finetuned_model(clause: str):
    try:
        res = finetune_client.chat.completions.create(
            model=FINETUNED_MODEL_ID,
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ê³„ì•½ì„œë¥¼ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ 1~4ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì„œ ë§í•˜ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": clause
                }
            ],
            temperature=0.2
        )

        return res.choices[0].message.content

    except Exception as e:
        print("âŒ íŒŒì¸íŠœë‹ ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨:", e)
        return "âš ï¸ í˜„ì¬ ì‰¬ìš´ ì„¤ëª… ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

# --------------------------------------------------------------------------
# 5. ì¼ë°˜ LLM (ìœ„í—˜ ìš”ì†Œ ë¶„ì„)
# --------------------------------------------------------------------------
def analyze_risk_with_general_llm(clause: str):
    prompt = f"""
ë‹¤ìŒ ê³„ì•½ì„œ ì¡°í•­ì—ì„œ ê·¼ë¡œìì—ê²Œ ë¶ˆë¦¬í•˜ê±°ë‚˜
ì£¼ì˜í•´ì•¼ í•  ìœ„í—˜ ìš”ì†Œë¥¼ 2~3ê°œ ìš”ì•½í•˜ê³ ,
ê° í•­ëª©ë§ˆë‹¤ ì™œ ìœ„í—˜í•œì§€ë„ ì„¤ëª…í•˜ì„¸ìš”.

{clause}
"""
    res = general_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return res.choices[0].message.content

# --------------------------------------------------------------------------
# 6. Streamlit ì±„íŒ…í˜• UI
# --------------------------------------------------------------------------
# --------------------------------------------------------------------------
# 6. Streamlit ì±„íŒ…í˜• UI (ì»¤ìŠ¤í…€ ë ˆì´ì•„ì›ƒ)
# --------------------------------------------------------------------------
st.set_page_config(
    page_title="ê³„ì•½ì„œ ì´í•´ AI",
    page_icon="ğŸ“„",
    layout="wide",
)

# ğŸ’„ ì „ì²´ ìŠ¤íƒ€ì¼
st.markdown(
    """
<style>
/* ì „ì²´ ë°°ê²½ */
body {
    background: #edf2f7;
}

/* Streamlit ê¸°ë³¸ ì—¬ë°± ì¡°ê¸ˆ ì¤„ì´ê¸° */
.block-container {
    padding-top: 3rem;
    padding-bottom: 3rem;
}

/* í˜ì´ì§€ ì¤‘ì•™ ì¹´ë“œ */
.app-bg {
    display: flex;
    justify-content: center;
}

.app-frame {
    width: 100%;
    max-width: 960px;
    background: #ffffff;
    border-radius: 18px;
    box-shadow: 0 12px 35px rgba(15, 35, 95, 0.12);
    padding: 24px 28px 28px;
}

/* ìƒë‹¨ ì œëª© ì˜ì—­ */
.header-row {
    display: flex;
    align-items: center;
    gap: 12px;
    margin-bottom: 10px;
}

.menu-icon {
    width: 30px;
    height: 30px;
    border-radius: 999px;
    border: 1px solid #d4e0f4;
    display: flex;
    align-items: center;
    justify-content: center;
}

.menu-icon-bar {
    width: 14px;
    height: 2px;
    border-radius: 999px;
    background: #4b6bb6;
    position: relative;
}
.menu-icon-bar::before,
.menu-icon-bar::after {
    content: "";
    position: absolute;
    width: 14px;
    height: 2px;
    border-radius: 999px;
    background: #4b6bb6;
    left: 0;
}
.menu-icon-bar::before { top: -4px; }
.menu-icon-bar::after  { top:  4px; }

.app-title {
    font-size: 26px;
    font-weight: 750;
    color: #1f2a4d;
}

.app-subtitle {
    font-size: 13px;
    color: #7a8aad;
}

/* ì±„íŒ… ì¹´ë“œ */
.chat-window {
    margin-top: 16px;
    background: #ffffff;
    border-radius: 18px;
    padding: 16px 20px 18px;
    box-shadow: 0 6px 18px rgba(15, 35, 95, 0.08);
    border: 1px solid #e0e9fb;
}

/* ì¹´í†¡ì²˜ëŸ¼ ê°€ìš´ë° ì¶• */
.chat-inner {
    max-width: 720px;
    margin: 0 auto;
}

/* í•œ ì¤„(í–‰) */
.chat-row {
    display: flex;
    align-items: flex-end;
    gap: 10px;
    margin-bottom: 12px;
}
.chat-row.user {
    justify-content: flex-end;
}

/* ì•„ë°”íƒ€ */
.avatar {
    width: 28px;
    height: 28px;
    border-radius: 999px;
    background: #e9f1ff;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 15px;
    color: #4b7cf5;
}
.avatar.bot {
    background: #edf1f9;
    color: #7b8baa;
}

/* ê¸°ë³¸ ë§í’ì„  */
.bubble {
    border-radius: 18px;
    padding: 10px 14px;
    font-size: 14px;
    line-height: 1.4;
    max-width: 420px;
    word-break: keep-all;
}
.bubble.user {
    background: #2f80ff;
    color: #ffffff;
    border-bottom-right-radius: 4px;
}
.bubble.bot {
    background: #ffffff;
    border: 1px solid #dfe7f5;
    color: #1f2937;
    border-bottom-left-radius: 4px;
}

/* ìµœì´ˆ ì¸ì‚¬ ì¹´ë“œ */
.bot-card {
    max-width: 520px;
    border-radius: 16px;
    border: 1px solid #dde5f2;
    background: #ffffff;
    padding: 10px 12px;
    display: flex;
    flex-direction: column;
    gap: 7px;
}
.bot-card-header {
    display: flex;
    align-items: center;
    gap: 8px;
    font-size: 13px;
    font-weight: 600;
    color: #34415f;
    padding-bottom: 6px;
    border-bottom: 1px solid #edf1f9;
}
.bot-card-avatar {
    width: 22px;
    height: 22px;
    border-radius: 999px;
    border: 1px solid #d1ddf5;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 13px;
}
.bot-card-body {
    font-size: 14px;
    line-height: 1.5;
    color: #2f3a54;
}

/* RAG ê²°ê³¼ ì¹´ë“œ */
.answer-card {
    max-width: 520px;
    border-radius: 16px;
    border: 1px solid #dfe7f5;
    background: #ffffff;
    padding: 10px 14px;
    font-size: 14px;
    line-height: 1.5;
}
.answer-section {
    margin-top: 8px;
    padding-top: 8px;
    border-top: 1px dashed #e4e9f5;
}
.answer-section:first-child {
    margin-top: 0;
    padding-top: 0;
    border-top: none;
}
.answer-section-title {
    font-weight: 600;
    margin-bottom: 4px;
    display: flex;
    align-items: center;
    gap: 4px;
    color: #1f2a4d;
}
.answer-section-body {
    font-size: 13.5px;
    color: #374151;
}

/* ì…ë ¥ì°½ë„ ê°€ìš´ë° ì •ë ¬ */
.stChatInput {
    margin-top: 1.2rem;
}
.stChatInput > div {
    max-width: 960px;
    margin: 0 auto;
}
</style>
""",
    unsafe_allow_html=True,
)

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” (ì²˜ìŒì— ì¸ì‚¬ ë©”ì‹œì§€ 1ê°œ)
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "ai",
            "type": "intro",
            "content": (
                "ì•ˆë…•í•˜ì„¸ìš”, ê³„ì•½ì„œ ì´í•´ AIì…ë‹ˆë‹¤.\n"
                "ê¶ê¸ˆí•œ ê³„ì•½ì„œ ì¡°í•­ì´ë‚˜ í‚¤ì›Œë“œë¥¼ ì•„ë˜ ì…ë ¥ì°½ì— ì ì–´ ì£¼ì„¸ìš”.\n"
                'ì˜ˆ: "ê·¼ë¡œì‹œê°„ ì¡°í•­ ì„¤ëª…í•´ì¤˜"'
            ),
        }
    ]

# --------------------------------------------------------------------------
# 7. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ (st.chat_input)
# --------------------------------------------------------------------------
docs, vectors = load_docs_and_vectors()
vectorstore = create_vectorstore(docs, vectors)
rag_chain = initialize_rag_chain(vectorstore)

user_query = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

if user_query:
    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    st.session_state.messages.append(
        {"role": "human", "type": "user", "content": user_query}
    )

    # 2) RAG ê²€ìƒ‰ + íŒŒì¸íŠœë‹ + ìœ„í—˜ë¶„ì„
    rag_response = rag_chain.invoke({"input": user_query})
    raw_clause = rag_response["answer"]

    # [íŒŒì¼ëª….json] ì œê±°
    clause = re.sub(r"\[[^\]]+\.json\]\s*", "", raw_clause)

    easy = explain_with_finetuned_model(clause)
    risk = analyze_risk_with_general_llm(clause)

    # 3) AI ë‹µë³€ êµ¬ì¡°í™”í•´ì„œ ì €ì¥
    st.session_state.messages.append(
        {
            "role": "ai",
            "type": "answer",
            "query": user_query,
            "clause": clause,
            "easy": easy,
            "risk": risk,
        }
    )

# --------------------------------------------------------------------------
# 8. ë ˆì´ì•„ì›ƒ ë Œë”ë§ (ë‹¨ìˆœ: ì›¹í˜ì´ì§€ ìœ„ì— ì±„íŒ…ë§Œ)
# --------------------------------------------------------------------------

# ìƒë‹¨ í”„ë ˆì„ ì—´ê¸°
st.markdown('<div class="chat-inner">', unsafe_allow_html=True)
# í—¤ë”
st.markdown(
    """
<div class="header-row">
  <div class="menu-icon">
    <div class="menu-icon-bar"></div>
  </div>
  <div>
    <div class="app-title">ê³„ì•½ì„œ ì´í•´ AI</div>
    <div class="app-subtitle">ê³„ì•½ì„œ ì¡°í•­ ê²€ìƒ‰ Â· ì‰¬ìš´ ì„¤ëª… Â· ìœ„í—˜ ìš”ì†Œ ë¶„ì„</div>
  </div>
</div>
""",
    unsafe_allow_html=True,
)

# ì±„íŒ… ì¹´ë“œ ì‹œì‘

# ë©”ì‹œì§€ë“¤ ë Œë”ë§
for msg in st.session_state.messages:
    if msg["role"] == "human":
        # ì‚¬ìš©ì(íŒŒë€ ë§í’ì„ )
        st.markdown(
            f"""
<div class="chat-row user">
  <div class="bubble user">{msg['content']}</div>
</div>
""",
            unsafe_allow_html=True,
        )
    else:
        # ìµœì´ˆ ì¸ì‚¬ ì¹´ë“œ
        if msg["type"] == "intro":
            body = msg["content"].replace("\n", "<br />")
            st.markdown(
                f"""
<div class="chat-row">
  <div class="avatar bot">ğŸ‘¤</div>
  <div class="bot-card">
    <div class="bot-card-header">
      <div class="bot-card-avatar">ğŸ¤–</div>
      <div>ê³„ì•½ì„œ ì´í•´ ë„ìš°ë¯¸</div>
    </div>
    <div class="bot-card-body">
      {body}
    </div>
  </div>
</div>
""",
                unsafe_allow_html=True,
            )
        # ë‹µë³€ ì¹´ë“œ
        elif msg["type"] == "answer":
            clause_html = msg["clause"].replace("\n", "<br />")
            easy_html = msg["easy"].replace("\n", "<br />")
            risk_html = msg["risk"].replace("\n", "<br />")

            st.markdown(
                f"""
<div class="chat-row">
  <div class="avatar bot">ğŸ‘¤</div>
  <div class="answer-card">
    <div class="answer-section">
      <div class="answer-section-title">ğŸ”µ ê´€ë ¨ ê³„ì•½ì„œ ì¡°í•­</div>
      <div class="answer-section-body">{clause_html}</div>
    </div>
    <div class="answer-section">
      <div class="answer-section-title">âœ¨ ì‰¬ìš´ ì„¤ëª…</div>
      <div class="answer-section-body">{easy_html}</div>
    </div>
    <div class="answer-section">
      <div class="answer-section-title">âš ï¸ ìœ„í—˜ ìš”ì†Œ ìš”ì•½</div>
      <div class="answer-section-body">{risk_html}</div>
    </div>
  </div>
</div>
""",
                unsafe_allow_html=True,
            )

# ì±„íŒ… ì¹´ë“œ / í”„ë ˆì„ ë‹«ê¸°
st.markdown("</div></div></div></div>", unsafe_allow_html=True)



