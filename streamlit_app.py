#streamlit cloud ì™€ ì—°ë™ì„ ìœ„í•´ lawchatapp ì½”ë“œë¥¼ ë³€í™˜ì‹œí‚¨ ì½”ë“œ ì…ë‹ˆë‹¤.
#Releaseì— ìˆëŠ” streamlit_app.pyë¥¼ ì‹¤í–‰ì‹œí‚¤ê¸° ìœ„í•œ ë°ì´í„° íŒŒì¼ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

import streamlit as st
import requests
import json
import zipfile
import io
import numpy as np
import faiss
import re

from openai import OpenAI

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain

# --------------------------------------------------------------------------
# 0. Streamlit ê¸°ë³¸ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(
    page_title="ê³„ì•½ì„œ ë„ìš°ë¯¸",
    page_icon="ğŸ“„",
    layout="wide",
)

# --------------------------------------------------------------------------
# 1. API Key (Streamlit Secrets ì‚¬ìš©)
# --------------------------------------------------------------------------
GENERAL_API_KEY = st.secrets.get("GENERAL_API_KEY")
FINETUNE_API_KEY = st.secrets.get("FINETUNE_API_KEY")

if not GENERAL_API_KEY or not FINETUNE_API_KEY:
    st.error(
        "ğŸ” API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
        "Streamlit Cloudì˜ **Manage app â†’ Settings â†’ Secrets** ì—ì„œ\n"
        "`GENERAL_API_KEY`, `FINETUNE_API_KEY` ê°’ì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”."
    )
    st.stop()

openai_client = OpenAI(api_key=GENERAL_API_KEY)
finetune_client = OpenAI(api_key=FINETUNE_API_KEY)

# âš ï¸ ë„ˆê°€ ë§Œë“  íŒŒì¸íŠœë‹ ëª¨ë¸ ID
FINETUNED_MODEL_ID = "ft:gpt-4.1-mini-2025-04-14:dbdbdeep::CiuSaiDu"

# --------------------------------------------------------------------------
# 2. GitHub Release ì—ì„œ ë¬¸ì„œ / ì„ë² ë”© ë‹¤ìš´ë¡œë“œ
# --------------------------------------------------------------------------
DOC_URL = "https://github.com/gimdoo/Text_Data_Analysis_team1/releases/download/v1.1/_documents.json"
EMB_URL = "https://github.com/gimdoo/Text_Data_Analysis_team1/releases/download/v1.1/_embeddings.zip"


@st.cache_resource
def download_and_load_data():
    # ---- ë¬¸ì„œ JSON ----
    doc_res = requests.get(DOC_URL)
    doc_res.raise_for_status()

    try:
        docs_json = json.loads(doc_res.text)
    except json.JSONDecodeError:
        st.error("ğŸ“„ ë¬¸ì„œ JSONì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. _documents.json í˜•ì‹ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        st.stop()

    # í˜•ì‹ ë°©ì–´: dict ë˜ëŠ” list ëª¨ë‘ ì²˜ë¦¬
    if isinstance(docs_json, dict) and "documents" in docs_json:
        docs = docs_json["documents"]
    elif isinstance(docs_json, list):
        docs = docs_json
    else:
        st.error("ğŸ“„ _documents.json í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. (list ë˜ëŠ” { 'documents': [...] } í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.)")
        st.stop()

    # ---- ì„ë² ë”© ZIP(npz) ----
    emb_res = requests.get(EMB_URL)
    emb_res.raise_for_status()

    zf = zipfile.ZipFile(io.BytesIO(emb_res.content))
    npz_files = [name for name in zf.namelist() if name.endswith(".npz")]

    if not npz_files:
        st.error("ğŸ“¦ _embeddings.zip ì•ˆì— .npz íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ì²« ë²ˆì§¸ npz ì‚¬ìš©
    with zf.open(npz_files[0]) as f:
        npz = np.load(f)
        if "arr_0" in npz.files:
            vectors = npz["arr_0"]
        else:
            # í‚¤ ì´ë¦„ì´ ë‹¤ë¥¸ ê²½ìš°: ì²« ë²ˆì§¸ ë°°ì—´ ì‚¬ìš©
            vectors = npz[npz.files[0]]

    return docs, vectors


# --------------------------------------------------------------------------
# 3. FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
# --------------------------------------------------------------------------
@st.cache_resource
def create_vectorstore(_docs, _vectors):
    # FAISS ì¸ë±ìŠ¤ ìƒì„±
    dim = _vectors.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(_vectors.astype("float32"))

    # LangChain ë¬¸ì„œ ë˜í•‘
    wrapped_docs = [
        Document(page_content=d) if isinstance(d, str) else d
        for d in _docs
    ]

    doc_dict = {str(i): wrapped_docs[i] for i in range(len(wrapped_docs))}
    docstore = InMemoryDocstore(doc_dict)
    index_to_docstore_id = {i: str(i) for i in range(len(wrapped_docs))}

    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=GENERAL_API_KEY,
    )

    vectorstore = FAISS(
        embedding_function=embeddings,  # ìµœì‹  ë²„ì „ì—ì„œë„ ë™ì‘
        index=index,
        docstore=docstore,
        index_to_docstore_id=index_to_docstore_id,
    )
    return vectorstore


# --------------------------------------------------------------------------
# 4. RAG ì²´ì¸ ì´ˆê¸°í™”
# --------------------------------------------------------------------------
@st.cache_resource
def initialize_rag_chain(_vectorstore):
    retriever = _vectorstore.as_retriever(search_kwargs={"k": 3})

    qa_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°í•­ ê²€ìƒ‰ AIì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µí•˜ì„¸ìš”.
âš ï¸ ë¬¸ì„œì˜ íŒŒì¼ëª…ì´ë‚˜ ì‹ë³„ìëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

{context}""",
            ),
            ("human", "{input}"),
        ]
    )

    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=0,
        api_key=GENERAL_API_KEY,
    )

    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)

    return rag_chain


# --------------------------------------------------------------------------
# 5. íŒŒì¸íŠœë‹ LLM (ì‰¬ìš´ ì„¤ëª…)
# --------------------------------------------------------------------------
def explain_with_finetuned_model(clause: str) -> str:
    try:
        res = finetune_client.chat.completions.create(
            model=FINETUNED_MODEL_ID,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ë‹¹ì‹ ì€ ê³„ì•½ì„œë¥¼ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. "
                        "ë°˜ë“œì‹œ 1~4ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì„œ ë§í•˜ì„¸ìš”."
                    ),
                },
                {"role": "user", "content": clause},
            ],
            temperature=0.2,
        )
        return res.choices[0].message.content
    except Exception as e:
        # ì—¬ê¸°ì„œ API Key / í”„ë¡œì íŠ¸ í‚¤ mismatch ê°™ì€ ì—ëŸ¬ë„ í¬ì°©ë¨
        return f"âš ï¸ í˜„ì¬ ì‰¬ìš´ ì„¤ëª… ëª¨ë¸ í˜¸ì¶œì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤: {e}"


# --------------------------------------------------------------------------
# 6. ì¼ë°˜ LLM (ìœ„í—˜ ìš”ì†Œ ë¶„ì„)
# --------------------------------------------------------------------------
def analyze_risk_with_general_llm(clause: str) -> str:
    prompt = f"""
ë‹¤ìŒ ê³„ì•½ì„œ ì¡°í•­ì—ì„œ ê·¼ë¡œìì—ê²Œ ë¶ˆë¦¬í•˜ê±°ë‚˜
ì£¼ì˜í•´ì•¼ í•  ìœ„í—˜ ìš”ì†Œë¥¼ 2~3ê°œ ìš”ì•½í•˜ê³ ,
ê° í•­ëª©ë§ˆë‹¤ ì™œ ìœ„í—˜í•œì§€ë„ ì„¤ëª…í•˜ì„¸ìš”.

{clause}
"""
    try:
        res = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
        )
        return res.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ ìœ„í—˜ ìš”ì†Œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


# --------------------------------------------------------------------------
# 7. UI ìŠ¤íƒ€ì¼ (ë„ˆê°€ ë§Œë“  ì¹´í†¡ ëŠë‚Œ ê·¸ëŒ€ë¡œ)
# --------------------------------------------------------------------------
st.markdown(
    """
<style>
/* ì „ì²´ ë°°ê²½ */
body {
    background: #edf2f7;
}

/* Streamlit ê¸°ë³¸ ì—¬ë°± ì¡°ê¸ˆ ì¤„ì´ê¸° */
.block-container {
    padding-top: 3rem;
    padding-bottom: 3rem;
}

/* ì¹´í†¡ì²˜ëŸ¼ ê°€ìš´ë° ì¶• */
.chat-inner {
    max-width: 720px;
    margin: 0 auto;
}

/* ìƒë‹¨ ì œëª© ì˜ì—­ */
.header-row {
    display: flex;
    align-items: center;
    gap: 12px;
    margin-bottom: 10px;
}

.menu-icon {
    width: 30px;
    height: 30px;
    border-radius: 999px;
    border: 1px solid #d4e0f4;
    display: flex;
    align-items: center;
    justify-content: center;
}

.menu-icon-bar {
    width: 14px;
    height: 2px;
    border-radius: 999px;
    background: #4b6bb6;
    position: relative;
}
.menu-icon-bar::before,
.menu-icon-bar::after {
    content: "";
    position: absolute;
    width: 14px;
    height: 2px;
    border-radius: 999px;
    background: #4b6bb6;
    left: 0;
}
.menu-icon-bar::before { top: -4px; }
.menu-icon-bar::after  { top:  4px; }

.app-title {
    font-size: 26px;
    font-weight: 750;
    color: #1f2a4d;
}

.app-subtitle {
    font-size: 13px;
    color: #7a8aad;
}

/* í•œ ì¤„(í–‰) */
.chat-row {
    display: flex;
    align-items: flex-end;
    gap: 10px;
    margin-bottom: 12px;
}
.chat-row.user {
    justify-content: flex-end;
}

/* ì•„ë°”íƒ€ */
.avatar {
    width: 28px;
    height: 28px;
    border-radius: 999px;
    background: #e9f1ff;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 15px;
    color: #4b7cf5;
}
.avatar.bot {
    background: #edf1f9;
    color: #7b8baa;
}

/* ê¸°ë³¸ ë§í’ì„  */
.bubble {
    border-radius: 18px;
    padding: 10px 14px;
    font-size: 14px;
    line-height: 1.4;
    max-width: 420px;
    word-break: keep-all;
}
.bubble.user {
    background: #2f80ff;
    color: #ffffff;
    border-bottom-right-radius: 4px;
}
.bubble.bot {
    background: #ffffff;
    border: 1px solid #dfe7f5;
    color: #1f2937;
    border-bottom-left-radius: 4px;
}

/* ìµœì´ˆ ì¸ì‚¬ ì¹´ë“œ */
.bot-card {
    max-width: 520px;
    border-radius: 16px;
    border: 1px solid #dde5f2;
    background: #ffffff;
    padding: 10px 12px;
    display: flex;
    flex-direction: column;
    gap: 7px;
}
.bot-card-header {
    display: flex;
    align-items: center;
    gap: 8px;
    font-size: 13px;
    font-weight: 600;
    color: #34415f;
    padding-bottom: 6px;
    border-bottom: 1px solid #edf1f9;
}
.bot-card-avatar {
    width: 22px;
    height: 22px;
    border-radius: 999px;
    border: 1px solid #d1ddf5;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 13px;
}
.bot-card-body {
    font-size: 14px;
    line-height: 1.5;
    color: #2f3a54;
}

/* RAG ê²°ê³¼ ì¹´ë“œ */
.answer-card {
    max-width: 520px;
    border-radius: 16px;
    border: 1px solid #dfe7f5;
    background: #ffffff;
    padding: 10px 14px;
    font-size: 14px;
    line-height: 1.5;
}
.answer-section {
    margin-top: 8px;
    padding-top: 8px;
    border-top: 1px dashed #e4e9f5;
}
.answer-section:first-child {
    margin-top: 0;
    padding-top: 0;
    border-top: none;
}
.answer-section-title {
    font-weight: 600;
    margin-bottom: 4px;
    display: flex;
    align-items: center;
    gap: 4px;
    color: #1f2a4d;
}
.answer-section-body {
    font-size: 13.5px;
    color: #374151;
}

/* ì…ë ¥ì°½ë„ ê°€ìš´ë° ì •ë ¬ */
.stChatInput {
    margin-top: 1.2rem;
}
.stChatInput > div {
    max-width: 960px;
    margin: 0 auto;
}
</style>
""",
    unsafe_allow_html=True,
)

# --------------------------------------------------------------------------
# 8. ì„¸ì…˜ ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
# --------------------------------------------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "ai",
            "type": "intro",
            "content": (
                "ì•ˆë…•í•˜ì„¸ìš”, ê³„ì•½ì„œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n"
                "ê¶ê¸ˆí•œ ê³„ì•½ì„œ ì¡°í•­ì´ë‚˜ í‚¤ì›Œë“œë¥¼ ì•„ë˜ ì…ë ¥ì°½ì— ì ì–´ ì£¼ì„¸ìš”.\n"
                'ì˜ˆ: "ê·¼ë¡œì‹œê°„ ì¡°í•­ ì„¤ëª…í•´ì¤˜"'
            ),
        }
    ]

# --------------------------------------------------------------------------
# 9. ë°ì´í„° / ì²´ì¸ ì¤€ë¹„
# --------------------------------------------------------------------------
docs, vectors = download_and_load_data()
vectorstore = create_vectorstore(docs, vectors)
rag_chain = initialize_rag_chain(vectorstore)

# --------------------------------------------------------------------------
# 10. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# --------------------------------------------------------------------------
user_query = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

if user_query:
    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    st.session_state.messages.append(
        {"role": "human", "type": "user", "content": user_query}
    )

    # 2) RAG ê²€ìƒ‰ + íŒŒì¸íŠœë‹ + ìœ„í—˜ ë¶„ì„
    rag_response = rag_chain.invoke({"input": user_query})
    raw_clause = rag_response.get("answer", "")

    # [íŒŒì¼ëª….json] ì œê±°
    clause = re.sub(r"\[[^\]]+\.json\]\s*", "", raw_clause)

    easy = explain_with_finetuned_model(clause)
    risk = analyze_risk_with_general_llm(clause)

    # 3) AI ë‹µë³€ êµ¬ì¡°í™”í•´ì„œ ì €ì¥
    st.session_state.messages.append(
        {
            "role": "ai",
            "type": "answer",
            "query": user_query,
            "clause": clause,
            "easy": easy,
            "risk": risk,
        }
    )

# --------------------------------------------------------------------------
# 11. ì±„íŒ… UI ë Œë”ë§
# --------------------------------------------------------------------------
st.markdown('<div class="chat-inner">', unsafe_allow_html=True)

# í—¤ë”
st.markdown(
    """
<div class="header-row">
  <div class="menu-icon">
    <div class="menu-icon-bar"></div>
  </div>
  <div>
    <div class="app-title">ê³„ì•½ì„œ ë„ìš°ë¯¸</div>
    <div class="app-subtitle">ê³„ì•½ì„œ ì¡°í•­ ê²€ìƒ‰ Â· ì‰¬ìš´ ì„¤ëª… Â· ìœ„í—˜ ìš”ì†Œ ë¶„ì„</div>
  </div>
</div>
""",
    unsafe_allow_html=True,
)

# ë©”ì‹œì§€ë“¤ ë Œë”ë§
for msg in st.session_state.messages:
    if msg["role"] == "human":
        # ì‚¬ìš©ì ë§í’ì„ 
        st.markdown(
            f"""
<div class="chat-row user">
  <div class="bubble user">{msg['content']}</div>
</div>
""",
            unsafe_allow_html=True,
        )
    else:
        if msg["type"] == "intro":
            body = msg["content"].replace("\n", "<br />")
            st.markdown(
                f"""
<div class="chat-row">
  <div class="avatar bot">ğŸ‘¤</div>
  <div class="bot-card">
    <div class="bot-card-header">
      <div class="bot-card-avatar">ğŸ¤–</div>
      <div>ê³„ì•½ì„œ ë„ìš°ë¯¸</div>
    </div>
    <div class="bot-card-body">
      {body}
    </div>
  </div>
</div>
""",
                unsafe_allow_html=True,
            )
        elif msg["type"] == "answer":
            clause_html = msg["clause"].replace("\n", "<br />")
            easy_html = msg["easy"].replace("\n", "<br />")
            risk_html = msg["risk"].replace("\n", "<br />")

            st.markdown(
                f"""
<div class="chat-row">
  <div class="avatar bot">ğŸ‘¤</div>
  <div class="answer-card">
    <div class="answer-section">
      <div class="answer-section-title">ğŸ”µ ê´€ë ¨ ê³„ì•½ì„œ ì¡°í•­</div>
      <div class="answer-section-body">{clause_html}</div>
    </div>
    <div class="answer-section">
      <div class="answer-section-title">âœ¨ ì‰¬ìš´ ì„¤ëª…</div>
      <div class="answer-section-body">{easy_html}</div>
    </div>
    <div class="answer-section">
      <div class="answer-section-title">âš ï¸ ìœ„í—˜ ìš”ì†Œ ìš”ì•½</div>
      <div class="answer-section-body">{risk_html}</div>
    </div>
  </div>
</div>
""",
                unsafe_allow_html=True,
            )

st.markdown("</div>", unsafe_allow_html=True)




