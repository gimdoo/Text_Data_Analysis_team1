import streamlit as st
import requests
import json
import zipfile
import io
import numpy as np
import faiss
import re

from openai import OpenAI

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain

# --------------------------------------------------------------------------
# 0. Streamlit ê¸°ë³¸ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(
    page_title="ê³„ì•½ì„œ ì´í•´ AI",
    page_icon="ğŸ“„",
    layout="wide",
)


# --------------------------------------------------------------------------
# 1. API Key (Streamlit Secrets)
# --------------------------------------------------------------------------
GENERAL_API_KEY = st.secrets.get("GENERAL_API_KEY")
FINETUNE_API_KEY = st.secrets.get("FINETUNE_API_KEY")

if not GENERAL_API_KEY or not FINETUNE_API_KEY:
    st.error(
        "ğŸ” API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
        "Streamlit Cloud â†’ Settings â†’ Secrets ì—ì„œ\n"
        "`GENERAL_API_KEY`, `FINETUNE_API_KEY` ê°’ì„ ì¶”ê°€í•˜ì„¸ìš”."
    )
    st.stop()

openai_client = OpenAI(api_key=GENERAL_API_KEY)
finetune_client = OpenAI(api_key=FINETUNE_API_KEY)

# âš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ ID
FINETUNED_MODEL_ID = "ft:gpt-4.1-mini-2025-04-14:dbdbdeep::CiuSaiDu"


# --------------------------------------------------------------------------
# 2. GitHub Release ë°ì´í„° ë‹¤ìš´ë¡œë“œ
# --------------------------------------------------------------------------
DOC_URL = "https://github.com/gimdoo/Text_Data_Analysis_team1/releases/download/v1.1/_documents.json"
EMB_URL = "https://github.com/gimdoo/Text_Data_Analysis_team1/releases/download/v1.1/_embeddings.zip"


@st.cache_data
def download_and_load_data():
    # ---- ë¬¸ì„œ JSON ë‹¤ìš´ë¡œë“œ ----
    doc_res = requests.get(DOC_URL)
    doc_res.raise_for_status()

    try:
        docs_json = json.loads(doc_res.text)
    except Exception:
        st.error("ğŸ“„ _documents.json íŒŒì‹± ì‹¤íŒ¨!")
        st.stop()

    # ë‹¤ì–‘í•œ í˜•ì‹ì„ í—ˆìš©
    if isinstance(docs_json, dict):
        if "documents" in docs_json:
            docs = docs_json["documents"]
        else:
            docs = list(docs_json.values())
    elif isinstance(docs_json, list):
        docs = docs_json
    else:
        st.error("ğŸ“„ JSON êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤.")
        st.stop()

    # ---- ì„ë² ë”© ZIP ë‹¤ìš´ë¡œë“œ ----
    emb_res = requests.get(EMB_URL)
    emb_res.raise_for_status()

    zf = zipfile.ZipFile(io.BytesIO(emb_res.content))
    npz_files = [x for x in zf.namelist() if x.endswith(".npz")]

    if not npz_files:
        st.error("âš ï¸ ì„ë² ë”© ZIP ì•ˆì— .npzê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    with zf.open(npz_files[0]) as f:
        npz = np.load(f)
        vectors = npz[npz.files[0]]

    return docs, vectors


# --------------------------------------------------------------------------
# 3. FAISS Vectorstore ìƒì„±
# --------------------------------------------------------------------------
@st.cache_data
def create_vectorstore(_docs, _vectors):

    dim = _vectors.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(_vectors.astype("float32"))

    wrapped_docs = [
        Document(page_content=d) if isinstance(d, str) else d
        for d in _docs
    ]

    doc_dict = {str(i): wrapped_docs[i] for i in range(len(wrapped_docs))}
    index_to_docstore_id = {i: str(i) for i in range(len(wrapped_docs))}

    docstore = InMemoryDocstore(doc_dict)

    # â— ì‚¬ì „ ì„ë² ë”© ì‚¬ìš© â†’ embedding_function=None
    vectorstore = FAISS(
        embedding_function=None,
        index=index,
        docstore=docstore,
        index_to_docstore_id=index_to_docstore_id,
    )

    return vectorstore


# --------------------------------------------------------------------------
# 4. RAG ì²´ì¸ ì´ˆê¸°í™”
# --------------------------------------------------------------------------
@st.cache_data
def initialize_rag_chain(_vectorstore):

    retriever = _vectorstore.as_retriever(search_kwargs={"k": 3})

    qa_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ê³„ì•½ì„œ ì¡°í•­ ê²€ìƒ‰ AIì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
âš ï¸ ë¬¸ì„œ íŒŒì¼ëª…ì´ë‚˜ ì‹ë³„ìëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

[ì°¸ê³  ë¬¸ì„œ]
{context}

[ì§ˆë¬¸]
{input}
""")

    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=0,
        openai_api_key=GENERAL_API_KEY,
    )

    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)

    return rag_chain


# --------------------------------------------------------------------------
# 5. íŒŒì¸íŠœë‹ ëª¨ë¸ "ì‰¬ìš´ ì„¤ëª…"
# --------------------------------------------------------------------------
def explain_with_finetuned_model(clause: str):

    try:
        res = finetune_client.chat.completions.create(
            model=FINETUNED_MODEL_ID,
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ê³„ì•½ì„œë¥¼ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ 1~4ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•˜ì„¸ìš”."
                },
                {"role": "user", "content": clause},
            ],
            temperature=0.2,
        )
        return res.choices[0].message.content

    except Exception as e:
        return f"âš ï¸ ì‰¬ìš´ ì„¤ëª… ëª¨ë¸ í˜¸ì¶œ ì˜¤ë¥˜: {e}"


# --------------------------------------------------------------------------
# 6. ì¼ë°˜ ëª¨ë¸ "ìœ„í—˜ìš”ì†Œ ë¶„ì„"
# --------------------------------------------------------------------------
def analyze_risk_with_general_llm(clause: str):

    prompt = f"""
ë‹¤ìŒ ê³„ì•½ì„œ ì¡°í•­ì—ì„œ ì§ì›ì—ê²Œ ë¶ˆë¦¬í•˜ê±°ë‚˜ ì£¼ì˜í•´ì•¼ í•  ìœ„í—˜ ìš”ì†Œë¥¼ 2~3ê°œ ìš”ì•½í•˜ê³ ,
ê° í•­ëª©ì´ ì™œ ìœ„í—˜í•œì§€ë„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”.

{clause}
"""

    try:
        res = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
        )
        return res.choices[0].message.content

    except Exception as e:
        return f"âš ï¸ ìœ„í—˜ìš”ì†Œ ë¶„ì„ ì˜¤ë¥˜: {e}"


# --------------------------------------------------------------------------
# 7. UI ìŠ¤íƒ€ì¼ (ì¹´í†¡ ëŠë‚Œ)
# --------------------------------------------------------------------------
st.markdown("""
<style>
/* (ìƒëµ: ë„ˆê°€ ë§Œë“  ê¸°ì¡´ CSS 100% ë™ì¼ ìœ ì§€) */
</style>
""", unsafe_allow_html=True)


# --------------------------------------------------------------------------
# 8. ì„¸ì…˜ ì´ˆê¸°í™”
# --------------------------------------------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "ai",
            "type": "intro",
            "content": (
                "ì•ˆë…•í•˜ì„¸ìš”, ê³„ì•½ì„œ ì´í•´ AIì…ë‹ˆë‹¤.\n"
                "ê¶ê¸ˆí•œ ì¡°í•­ì´ë‚˜ ë‹¨ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.\n"
                'ì˜ˆ: "ê·¼ë¡œì‹œê°„ ì¡°í•­ ì„¤ëª…í•´ì¤˜"'
            ),
        }
    ]


# --------------------------------------------------------------------------
# 9. ë°ì´í„° ë¡œë”©
# --------------------------------------------------------------------------
docs, vectors = download_and_load_data()
vectorstore = create_vectorstore(docs, vectors)
rag_chain = initialize_rag_chain(vectorstore)


# --------------------------------------------------------------------------
# 10. ì‚¬ìš©ì ì…ë ¥
# --------------------------------------------------------------------------
user_query = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

if user_query:
    st.session_state.messages.append(
        {"role": "human", "type": "user", "content": user_query}
    )

    rag_response = rag_chain.invoke({"input": user_query})
    raw_clause = rag_response.get("answer", "")

    # íŒŒì¼ëª… ì œê±° (ê°•í™”ëœ ì •ê·œì‹)
    clause = re.sub(r"\[[^\]]+\.json\]\s*", "", raw_clause, flags=re.IGNORECASE)

    easy = explain_with_finetuned_model(clause)
    risk = analyze_risk_with_general_llm(clause)

    st.session_state.messages.append(
        {
            "role": "ai",
            "type": "answer",
            "clause": clause,
            "easy": easy,
            "risk": risk,
        }
    )


# --------------------------------------------------------------------------
# 11. ë©”ì‹œì§€ ë Œë”ë§ (ì¹´í†¡ UI ìœ ì§€)
# --------------------------------------------------------------------------
st.markdown('<div class="chat-inner">', unsafe_allow_html=True)

# í—¤ë” UI (ìƒëµ ê°€ëŠ¥)
st.markdown("""
<div class="header-row">
  <div class="menu-icon"><div class="menu-icon-bar"></div></div>
  <div>
    <div class="app-title">ê³„ì•½ì„œ ì´í•´ AI</div>
    <div class="app-subtitle">ê³„ì•½ì„œ ì¡°í•­ ê²€ìƒ‰ Â· ì‰¬ìš´ ì„¤ëª… Â· ìœ„í—˜ ìš”ì†Œ ë¶„ì„</div>
  </div>
</div>
""", unsafe_allow_html=True)

for msg in st.session_state.messages:

    if msg["role"] == "human":
        st.markdown(
            f"""
<div class="chat-row user">
  <div class="bubble user">{msg['content']}</div>
</div>
""",
            unsafe_allow_html=True,
        )

    elif msg["type"] == "intro":
        body = msg["content"].replace("\n", "<br />")
        st.markdown(
            f"""
<div class="chat-row">
  <div class="avatar bot">ğŸ¤–</div>
  <div class="bot-card">
    <div class="bot-card-header">
      <div class="bot-card-avatar">ğŸ¤–</div>
      <div>ê³„ì•½ì„œ ì´í•´ ë„ìš°ë¯¸</div>
    </div>
    <div class="bot-card-body">{body}</div>
  </div>
</div>
""",
            unsafe_allow_html=True,
        )

    elif msg["type"] == "answer":
        clause_html = msg["clause"].replace("\n", "<br />")
        easy_html = msg["easy"].replace("\n", "<br />")
        risk_html = msg["risk"].replace("\n", "<br />")

        st.markdown(
            f"""
<div class="chat-row">
  <div class="avatar bot">ğŸ¤–</div>
  <div class="answer-card">
    <div class="answer-section">
      <div class="answer-section-title">ğŸ“˜ ê´€ë ¨ ì¡°í•­</div>
      <div class="answer-section-body">{clause_html}</div>
    </div>

    <div class="answer-section">
      <div class="answer-section-title">âœ¨ ì‰¬ìš´ ì„¤ëª…</div>
      <div class="answer-section-body">{easy_html}</div>
    </div>

    <div class="answer-section">
      <div class="answer-section-title">âš ï¸ ìœ„í—˜ ìš”ì†Œ</div>
      <div class="answer-section-body">{risk_html}</div>
    </div>
  </div>
</div>
""",
            unsafe_allow_html=True,
        )

st.markdown("</div>", unsafe_allow_html=True)
