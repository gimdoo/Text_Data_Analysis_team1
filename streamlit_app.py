import streamlit as st
import requests
import json
import re
import numpy as np
import faiss
import zipfile
import io

from openai import OpenAI
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate


# ---------------------------------------------------------
# 0. API Key ì„¤ì • (Streamlit Secrets)
# ---------------------------------------------------------
st.set_page_config(page_title="ê³„ì•½ì„œ ì´í•´ AI", layout="wide")

GENERAL_API_KEY = st.secrets["GENERAL_API_KEY"]
FINETUNE_API_KEY = st.secrets["FINETUNE_API_KEY"]

openai_client = OpenAI(api_key=GENERAL_API_KEY)
finetune_client = OpenAI(api_key=FINETUNE_API_KEY)

FINETUNED_MODEL = "ft:gpt-4.1-mini-2025-04-14:dbdbdeep::CiuSaiDu"


# ---------------------------------------------------------
# 1. GitHub Release íŒŒì¼ URL
# ---------------------------------------------------------
DOC_URL = "https://github.com/gimdoo/Text_Data_Analysis_team1/releases/download/v1.1/_documents.json"
EMB_ZIP_URL = "https://github.com/gimdoo/Text_Data_Analysis_team1/releases/download/v1.1/_embeddings.zip"


# ---------------------------------------------------------
# 2. ë¬¸ì„œ ë¡œë“œ(JSON)
# ---------------------------------------------------------
@st.cache_resource
def load_documents():
    res = requests.get(DOC_URL)
    res.raise_for_status()
    return json.loads(res.text)

docs = load_documents()


# ---------------------------------------------------------
# 3. ì„ë² ë”© ë¡œë“œ(.zip â†’ .npz)
# ---------------------------------------------------------
@st.cache_resource
def load_embeddings():
    res = requests.get(EMB_ZIP_URL)
    res.raise_for_status()

    z = zipfile.ZipFile(io.BytesIO(res.content))
    npz = np.load(z.open("_embeddings.npz"))
    return npz["arr_0"]

vectors = load_embeddings()


# ---------------------------------------------------------
# 4. FAISS VectorStore ìƒì„±
# ---------------------------------------------------------
@st.cache_resource
def create_vectorstore(docs, vectors):
    dim = len(vectors[0])
    index = faiss.IndexFlatL2(dim)
    index.add(vectors.astype("float32"))

    wrapped_docs = [Document(page_content=d) for d in docs]
    doc_dict = {str(i): wrapped_docs[i] for i in range(len(docs))}
    docstore = InMemoryDocstore(doc_dict)
    index_to_docstore_id = {i: str(i) for i in range(len(docs))}

    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=GENERAL_API_KEY,
    )

    return FAISS(
        embedding_function=embeddings,
        index=index,
        docstore=docstore,
        index_to_docstore_id=index_to_docstore_id,
    )

vectorstore = create_vectorstore(docs, vectors)
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})


# ---------------------------------------------------------
# 5. RAG ê²€ìƒ‰ (ìµœì‹  LangChain ë°©ì‹)
# ---------------------------------------------------------
def search_clause(query):
    results = retriever.invoke(query)   # ğŸ”¥ ìµœì‹  ë°©ì‹
    return "\n\n".join([d.page_content for d in results])


# ---------------------------------------------------------
# 6. íŒŒì¸íŠœë‹ ëª¨ë¸: ì‰¬ìš´ ì„¤ëª…
# ---------------------------------------------------------
def explain_easy(clause: str):
    try:
        res = finetune_client.chat.completions.create(
            model=FINETUNED_MODEL,
            messages=[
                {"role": "system", "content": "ê³„ì•½ì„œë¥¼ ì‰½ê³  ì§§ê²Œ ì„¤ëª…í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": clause},
            ],
            temperature=0.2,
        )
        return res.choices[0].message.content

    except Exception as e:
        return f"âš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ ì˜¤ë¥˜: {e}"


# ---------------------------------------------------------
# 7. GPT-4o: ìœ„í—˜ ë¶„ì„
# ---------------------------------------------------------
def analyze_risk(clause: str):
    prompt = f"""
ë‹¤ìŒ ê³„ì•½ì„œ ì¡°í•­ì—ì„œ ê·¼ë¡œìì—ê²Œ ë¶ˆë¦¬í•˜ê±°ë‚˜ ì£¼ì˜í•´ì•¼ í•  ìœ„í—˜ ìš”ì†Œë¥¼ 2~3ê°œ ìš”ì•½í•˜ì„¸ìš”.
ê° í•­ëª©ì´ ì™œ ìœ„í—˜í•œì§€ë„ ì„¤ëª…í•˜ì„¸ìš”.

{clause}
"""
    res = openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
    )
    return res.choices[0].message.content


# ---------------------------------------------------------
# 8. Streamlit UI
# ---------------------------------------------------------
st.title("ğŸ“„ ê³„ì•½ì„œ ì´í•´ AI")
st.write("ê³„ì•½ì„œ ì¡°í•­ì„ ê²€ìƒ‰í•˜ê³ , ì‰¬ìš´ ì„¤ëª… + ìœ„í—˜ ìš”ì†Œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")

user_query = st.text_input("ê¶ê¸ˆí•œ ê³„ì•½ì„œ ì¡°í•­ì„ ì…ë ¥í•˜ì„¸ìš”:")

if user_query:
    st.subheader("ğŸ” RAG ê²€ìƒ‰ ê²°ê³¼")
    raw_clause = search_clause(user_query)

    clause = re.sub(r"\[[^\]]+\.json\]\s*", "", raw_clause)
    st.write(clause)

    st.subheader("âœ¨ ì‰¬ìš´ ì„¤ëª… (íŒŒì¸íŠœë‹ ëª¨ë¸)")
    st.write(explain_easy(clause))

    st.subheader("âš ï¸ ìœ„í—˜ ìš”ì†Œ ë¶„ì„ (gpt-4o)")
    st.write(analyze_risk(clause))
