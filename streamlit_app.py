import streamlit as st
import os
import json
import zipfile
import requests
import numpy as np
import faiss
import re

from io import BytesIO
from openai import OpenAI

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain


# ============================================================
# 0. í™˜ê²½ ë³€ìˆ˜ (Streamlit Cloud Secrets ì‚¬ìš©)
# ============================================================
GENERAL_API_KEY = st.secrets["GENERAL_API_KEY"]
FINETUNE_API_KEY = st.secrets["FINETUNE_API_KEY"]

os.environ["OPENAI_API_KEY"] = GENERAL_API_KEY

general_client = OpenAI(api_key=GENERAL_API_KEY)
finetune_client = OpenAI(api_key=FINETUNE_API_KEY)

FINETUNED_MODEL_ID = "ft:gpt-4.1-mini-2025-04-14:dbdbdeep::CiuSaiDu"


# ============================================================
# 1. Release v1.1 íŒŒì¼ ë‹¤ìš´ë¡œë“œ
# ============================================================

DOC_URL = "https://github.com/gimdoo/Text_Data_Analysis_team1/releases/download/v1.1/_documents.json"
EMB_URL = "https://github.com/gimdoo/Text_Data_Analysis_team1/releases/download/v1.1/_embeddings.zip"


@st.cache_resource
def download_and_load_data():
    # ---- documents.json ë‹¤ìš´ë¡œë“œ ----
    doc_res = requests.get(DOC_URL)
    docs_json = json.loads(doc_res.content)

    docs = docs_json["documents"]  # ë¦¬ìŠ¤íŠ¸ of í…ìŠ¤íŠ¸

    # ---- embeddings.zip ë‹¤ìš´ë¡œë“œ ----
    emb_res = requests.get(EMB_URL)
    zip_bytes = BytesIO(emb_res.content)

    with zipfile.ZipFile(zip_bytes, "r") as z:
        vecs = np.load(BytesIO(z.read("_embeddings.npy")))

    return docs, vecs


# ============================================================
# 2. VectorStore ìƒì„±
# ============================================================
@st.cache_resource
def create_vectorstore(_docs, _vectors):
    dim = _vectors.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(np.array(_vectors).astype("float32"))

    wrapped = [Document(page_content=d) for d in _docs]
    doc_dict = {str(i): wrapped[i] for i in range(len(wrapped))}
    docstore = InMemoryDocstore(doc_dict)
    mapping = {i: str(i) for i in range(len(wrapped))}

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    vs = FAISS(
        embedding_function=embeddings,
        index=index,
        docstore=docstore,
        index_to_docstore_id=mapping,
    )
    return vs


# ============================================================
# 3. RAG Chain êµ¬ì„±
# ============================================================
@st.cache_resource
def build_rag(vs):
    retriever = vs.as_retriever(search_kwargs={"k": 3})

    qa_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
ë‹¹ì‹ ì€ ê³„ì•½ì„œ ê²€ìƒ‰ AIì…ë‹ˆë‹¤.
ì•„ë˜ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì •í™•í•˜ê²Œ ë°˜í™˜í•˜ì„¸ìš”.
ë¬¸ì„œ íŒŒì¼ëª…ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

{context}
""",
            ),
            ("human", "{input}"),
        ]
    )

    llm = ChatOpenAI(model="gpt-4o", temperature=0)

    doc_chain = create_stuff_documents_chain(llm, qa_prompt)
    rag_chain = create_retrieval_chain(retriever, doc_chain)

    return rag_chain


# ============================================================
# 4. ì‰¬ìš´ ì„¤ëª… (íŒŒì¸íŠœë‹ ëª¨ë¸)
# ============================================================
def explain_with_finetuned_model(clause):
    try:
        res = finetune_client.chat.completions.create(
            model=FINETUNED_MODEL_ID,
            messages=[
                {
                    "role": "system",
                    "content": "ê³„ì•½ì„œë¥¼ ì´ˆë“±í•™ìƒë„ ì´í•´í•˜ê²Œ ì‰½ê²Œ ìš”ì•½í•´ì¤˜. ë°˜ë“œì‹œ 1~4ë¬¸ì¥.",
                },
                {"role": "user", "content": clause},
            ],
        )
        return res.choices[0].message.content
    except:
        return "âš ï¸ ì‰¬ìš´ ì„¤ëª… ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."


# ============================================================
# 5. ìœ„í—˜ ìš”ì†Œ ë¶„ì„
# ============================================================
def analyze_risk_with_general_llm(clause):
    prompt = f"""
ë‹¤ìŒ ê³„ì•½ì„œ ì¡°í•­ì—ì„œ ê·¼ë¡œìì—ê²Œ ë¶ˆë¦¬í•  ìˆ˜ ìˆëŠ” ìœ„í—˜ ìš”ì†Œë¥¼ 2~3ê°œ ì°¾ê³ ,
ê°ê° ì™œ ìœ„í—˜í•œì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

{clause}
"""
    res = general_client.chat.completions.create(
        model="gpt-4o", messages=[{"role": "user", "content": prompt}]
    )
    return res.choices[0].message.content


# ============================================================
# 6. UI ìŠ¤íƒ€ì¼ (ì¹´í†¡í˜•)
# ============================================================
st.set_page_config(page_title="ê³„ì•½ì„œ ì´í•´ AI", layout="wide")

st.markdown(
    """
<style>
body { background:#ecf0f7; }
.block-container { padding-top:2rem; }

/* ì±„íŒ… ìŠ¤íƒ€ì¼ */
.chat-row { display:flex; margin-bottom:12px; }
.chat-row.user { justify-content:flex-end; }
.bubble {
    padding:10px 14px;
    border-radius:16px;
    max-width:420px;
    line-height:1.4;
}
.bubble.user {
    background:#2f80ff; color:white;
    border-bottom-right-radius:4px;
}
.bubble.bot {
    background:white;
    border:1px solid #d8e2f1;
    border-bottom-left-radius:4px;
}
.answer-card{
    padding:12px; border-radius:16px;
    border:1px solid #d8e2f1;
    background:#fff;
}
.answer-title{ font-weight:600; margin-bottom:6px; }
</style>
""",
    unsafe_allow_html=True,
)

# ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "ai",
            "type": "intro",
            "content": "ì•ˆë…•í•˜ì„¸ìš”! ê³„ì•½ì„œ ì´í•´ AIì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì¡°í•­ì„ ê²€ìƒ‰í•´ë³´ì„¸ìš”.",
        }
    ]


# ============================================================
# 7. ë°ì´í„° ë¡œë“œ + RAG ì¤€ë¹„
# ============================================================
docs, vectors = download_and_load_data()
vectorstore = create_vectorstore(docs, vectors)
rag_chain = build_rag(vectorstore)


# ============================================================
# 8. ì±„íŒ… ì…ë ¥
# ============================================================
user_query = st.chat_input("ê²€ìƒ‰í•  ê³„ì•½ì„œ ì¡°í•­ì„ ì…ë ¥í•˜ì„¸ìš”.")

if user_query:
    st.session_state.messages.append(
        {"role": "human", "type": "user", "content": user_query}
    )

    rag_out = rag_chain.invoke({"input": user_query})
    clause_raw = rag_out["answer"]
    clause_raw = re.sub(r"\\[[^\\]]+\\]", "", clause_raw)

    easy = explain_with_finetuned_model(clause_raw)
    risk = analyze_risk_with_general_llm(clause_raw)

    st.session_state.messages.append(
        {
            "role": "ai",
            "type": "answer",
            "clause": clause_raw,
            "easy": easy,
            "risk": risk,
        }
    )


# ============================================================
# 9. ë Œë”ë§
# ============================================================
for msg in st.session_state.messages:
    if msg["role"] == "human":
        st.markdown(
            f"""
<div class="chat-row user">
    <div class="bubble user">{msg['content']}</div>
</div>
""",
            unsafe_allow_html=True,
        )

    elif msg["type"] == "intro":
        st.markdown(
            f"""
<div class="chat-row">
    <div class="bubble bot">{msg['content']}</div>
</div>
""",
            unsafe_allow_html=True,
        )

    elif msg["type"] == "answer":
        st.markdown(
            f"""
<div class="chat-row">
    <div class="answer-card">
        <div class="answer-title">ğŸ”µ ê´€ë ¨ ê³„ì•½ì„œ ì¡°í•­</div>
        <div>{msg['clause']}</div>

        <div class="answer-title" style="margin-top:10px;">âœ¨ ì‰¬ìš´ ì„¤ëª…</div>
        <div>{msg['easy']}</div>

        <div class="answer-title" style="margin-top:10px;">âš ï¸ ìœ„í—˜ ìš”ì†Œ ë¶„ì„</div>
        <div>{msg['risk']}</div>
    </div>
</div>
""",
            unsafe_allow_html=True,
        )
