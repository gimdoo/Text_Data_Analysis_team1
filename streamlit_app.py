import streamlit as st
import pickle
import requests
import numpy as np
import faiss
import re
from openai import OpenAI
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate


# ---------------------------------------------------------
# 0. API í‚¤ ì…ë ¥
# ---------------------------------------------------------
st.set_page_config(page_title="ê³„ì•½ì„œ ì´í•´ AI", layout="wide")

GENERAL_API_KEY = st.secrets["GENERAL_API_KEY"]
FINETUNE_API_KEY = st.secrets["FINETUNE_API_KEY"]

openai_client = OpenAI(api_key=GENERAL_API_KEY)
finetune_client = OpenAI(api_key=FINETUNE_API_KEY)

FINETUNED_MODEL = "ft:gpt-4.1-mini-2025-04-14:dbdbdeep::CiuSaiDu"


# ---------------------------------------------------------
# 1. GitHub Release íŒŒì¼ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
# ---------------------------------------------------------
@st.cache_resource
def load_pickle_from_url(url: str):
    res = requests.get(url)
    return pickle.loads(res.content)


DOC_URL = "https://github.com/gimdoo/Text_Data_Analysis_team1/releases/download/v1.0/_documents.pkl"
EMB_URL = "https://github.com/gimdoo/Text_Data_Analysis_team1/releases/download/v1.0/_embeddings.pkl"

docs = load_pickle_from_url(DOC_URL)
vectors = load_pickle_from_url(EMB_URL)


# ---------------------------------------------------------
# 2. FAISS VectorStore ìƒì„±
# ---------------------------------------------------------
@st.cache_resource
def create_vectorstore(docs, vectors):
    dim = len(vectors[0])
    index = faiss.IndexFlatL2(dim)
    index.add(np.array(vectors).astype("float32"))

    wrapped_docs = [Document(page_content=d) for d in docs]
    doc_dict = {str(i): wrapped_docs[i] for i in range(len(docs))}
    docstore = InMemoryDocstore(doc_dict)
    index_to_docstore_id = {i: str(i) for i in range(len(docs))}

    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=GENERAL_API_KEY,
    )

    vectorstore = FAISS(
        embedding_function=embeddings,
        index=index,
        docstore=docstore,
        index_to_docstore_id=index_to_docstore_id,
    )

    return vectorstore


vectorstore = create_vectorstore(docs, vectors)
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})


# ---------------------------------------------------------
# 3. RAG ë‹µë³€ ìƒì„±
# ---------------------------------------------------------
def search_clause(query):
    results = retriever.get_relevant_documents(query)
    combined = "\n\n".join([d.page_content for d in results])
    return combined


# ---------------------------------------------------------
# 4. íŒŒì¸íŠœë‹ ëª¨ë¸ë¡œ ì‰¬ìš´ ì„¤ëª…
# ---------------------------------------------------------
def explain_easy(clause: str):
    try:
        completion = finetune_client.chat.completions.create(
            model=FINETUNED_MODEL,
            messages=[
                {"role": "system", "content": "ê³„ì•½ì„œë¥¼ ì‰½ê³  ì§§ê²Œ ì„¤ëª…í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": clause},
            ],
            temperature=0.2,
        )
        return completion.choices[0].message.content

    except Exception as e:
        return f"âš ï¸ ì‰¬ìš´ ì„¤ëª… ëª¨ë¸ ì˜¤ë¥˜: {e}"


# ---------------------------------------------------------
# 5. ìœ„í—˜ ë¶„ì„(gpt-4o)
# ---------------------------------------------------------
def analyze_risk(clause: str):
    prompt = f"""
ë‹¤ìŒ ê³„ì•½ì„œ ì¡°í•­ì—ì„œ ê·¼ë¡œìì—ê²Œ ë¶ˆë¦¬í•˜ê±°ë‚˜ ì£¼ì˜í•´ì•¼ í•  ìœ„í—˜ ìš”ì†Œë¥¼ 2~3ê°œ ìš”ì•½í•˜ì„¸ìš”.
ê·¸ë¦¬ê³  ê° í•­ëª©ì´ ì™œ ìœ„í—˜í•œì§€ë„ ì„¤ëª…í•˜ì„¸ìš”.

{clause}
"""

    completion = openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
    )
    return completion.choices[0].message.content


# ---------------------------------------------------------
# 6. Streamlit UI
# ---------------------------------------------------------
st.title("ğŸ“„ ê³„ì•½ì„œ ì´í•´ AI")
st.write("ê³„ì•½ì„œ ì¡°í•­ì„ ê²€ìƒ‰í•˜ê³ , ì‰¬ìš´ ì„¤ëª… + ìœ„í—˜ ìš”ì†Œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")

user_query = st.text_input("ê¶ê¸ˆí•œ ê³„ì•½ì„œ ì¡°í•­ì„ ì…ë ¥í•˜ì„¸ìš”:")

if user_query:
    st.subheader("ğŸ” RAG ê²€ìƒ‰ ê²°ê³¼")
    clause = search_clause(user_query)

    # JSON íŒŒì¼ëª… ì œê±°
    clause_clean = re.sub(r"\[[^\]]+\.json\]\s*", "", clause)

    st.write(clause_clean)

    st.subheader("âœ¨ ì‰¬ìš´ ì„¤ëª… (íŒŒì¸íŠœë‹ ëª¨ë¸)")
    st.write(explain_easy(clause_clean))

    st.subheader("âš ï¸ ìœ„í—˜ ìš”ì†Œ ë¶„ì„ (gpt-4o)")
    st.write(analyze_risk(clause_clean))
